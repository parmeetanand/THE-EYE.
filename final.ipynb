{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "martial-concrete",
   "metadata": {},
   "source": [
    "# Facial Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "concerned-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import face_recognition\n",
    "import cv2\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ongoing-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = pyttsx3.init()\n",
    "rate = engine.getProperty('rate')   # getting details of current speaking rate\n",
    "engine.setProperty('rate', 125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stupid-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stored_encodings():\n",
    "    dir = \"C:/Users/User/Documents/capstone/website_practice/upload/train/\"\n",
    "    known_face_names = os.listdir(dir)\n",
    "    known_face_encodings = []\n",
    "    for name in known_face_names:\n",
    "        name = face_recognition.load_image_file(dir + name)\n",
    "        encodings = face_recognition.face_encodings(name)[0]\n",
    "        known_face_encodings.append(encodings)\n",
    "    return known_face_encodings, known_face_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "metric-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_img():\n",
    "    \"\"\"capturing an image with the camera\"\"\"\n",
    "    cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "    check, frame = cap.read()\n",
    "    cap.release()\n",
    "    if check:\n",
    "        return frame\n",
    "    else:\n",
    "        if engine._inLoop:\n",
    "            engine.endLoop()\n",
    "        engine.say(\"Cannot record\")\n",
    "        engine.runAndWait()\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "thrown-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recog():\n",
    "    if engine._inLoop:\n",
    "        engine.endLoop()\n",
    "    photo = capture_img()\n",
    "    name_of_person = 'Unknown face'\n",
    "    #if photo.all() != 0:\n",
    "    all_face_locations = []\n",
    "    all_face_encodings = []\n",
    "    all_matches = []\n",
    "    known_face_encodings, known_face_names = stored_encodings()\n",
    "    current_frame_small = cv2.resize(photo,(0,0),fx=0.25,fy=0.25)\n",
    "    all_face_locations = face_recognition.face_locations(current_frame_small)\n",
    "    all_face_encodings = face_recognition.face_encodings(current_frame_small,all_face_locations)\n",
    "    for current_face_location,current_face_encoding in zip(all_face_locations,all_face_encodings):\n",
    "        top_pos,right_pos,bottom_pos,left_pos = current_face_location\n",
    "        top_pos = top_pos*4\n",
    "        right_pos = right_pos*4\n",
    "        bottom_pos = bottom_pos*4\n",
    "        left_pos = left_pos*4\n",
    "        all_matches = face_recognition.compare_faces(known_face_encodings, current_face_encoding)\n",
    "        \n",
    "    if True in all_matches:\n",
    "        first_match_index = all_matches.index(True)\n",
    "        name = known_face_names[first_match_index]\n",
    "        name_of_person = name.split(\".\", 1)        \n",
    "        cv2.rectangle(photo,(left_pos,top_pos),(right_pos,bottom_pos),(255,0,0),2)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(photo, name_of_person[0], (left_pos,bottom_pos), font, 1, (255,255,255),2)     \n",
    "        cv2.imwrite(\"C:/Users/User/Documents/capstone/website_practice/static/capture.png\", photo) \n",
    "        engine.say(f\"There is {name_of_person[0]} in front of you\")\n",
    "        engine.runAndWait()\n",
    "        return name_of_person[0]\n",
    "    else: \n",
    "        photo = cv2.imread(\"C:/Users/User/Documents/capstone/website_practice/static/Unknown.jpg\")\n",
    "        cv2.imwrite(\"C:/Users/User/Documents/capstone/website_practice/static/capture.png\", photo)\n",
    "        engine.say(\"Cannot Recognize\")\n",
    "        engine.runAndWait()\n",
    "        return name_of_person\n",
    "    return redirect(url_for('detect_face'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-bobby",
   "metadata": {},
   "source": [
    "# Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "binding-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from google.cloud import vision\n",
    "from gtts import gTTS\n",
    "import numpy\n",
    "from playsound import playsound\n",
    "import argparse\n",
    "from PIL import Image, ImageDraw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "light-trademark",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"object_detection.json\"\n",
    "\n",
    "\n",
    "def speaker(text):\n",
    "    \"\"\"returning results with the speaker\"\"\"\n",
    "    try:\n",
    "        gTTS(text=text, lang=\"en\").save(f\"{text.split()[0]}.mp3\")\n",
    "        playsound(f\"{text.split()[0]}.mp3\")\n",
    "        os.remove(f\"{text.split()[0]}.mp3\")\n",
    "    except Exception:\n",
    "        print(\"Could not activate the speaker\")\n",
    "\n",
    "\n",
    "def capture_img():\n",
    "    \"\"\"capturing an image with the camera\"\"\"\n",
    "    cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)  # make sure back camera is accessed, not front\n",
    "    check, frame = cap.read()\n",
    "    cap.release()\n",
    "    if check:\n",
    "        return frame\n",
    "    else:\n",
    "        speaker(\"I didn't manage to take a picture\")\n",
    "\n",
    "\n",
    "def save_img(frame):\n",
    "    \"\"\"saving the image in the file 'capture.png'\"\"\"\n",
    "    frame.dtype = numpy.uint8\n",
    "    cv2.imwrite(\"capture.png\", frame)\n",
    "\n",
    "\n",
    "def google_vision(photo):\n",
    "    \"\"\"detecting objects on the photo with Google Vision API\"\"\"\n",
    "    google_vision.vects = []\n",
    "    objects = []\n",
    "    result = ''\n",
    "    try:\n",
    "        client = vision.ImageAnnotatorClient()\n",
    "        with open(photo, 'rb') as image_file:\n",
    "            content = image_file.read()\n",
    "        image = vision.Image(content=content)\n",
    "        objects = client.object_localization(image=image).localized_object_annotations\n",
    "        if objects:\n",
    "            for num, object_ in enumerate(objects):\n",
    "                if len(objects) > 1 and num == len(objects) - 2:\n",
    "                    result += object_.name + ' and '\n",
    "                else:\n",
    "                    result += object_.name+', '\n",
    "            speaker(f\"There is probably {result} in front of you\")\n",
    "        else:\n",
    "            speaker(\"I could not find anything.\")\n",
    "    except Exception:\n",
    "        speaker(\"I could not perform an image search.\")\n",
    "        \n",
    "    for ob in objects:\n",
    "        for vertex in ob.bounding_poly.normalized_vertices:\n",
    "\n",
    "            google_vision.vects.append([vertex.x, vertex.y])\n",
    "    im = Image.open(photo)\n",
    "    width , height = im.size\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    for vertex in objects:\n",
    "        draw.polygon([\n",
    "            vertex.bounding_poly.normalized_vertices[0].x *width, vertex.bounding_poly.normalized_vertices[0].y*height,\n",
    "            vertex.bounding_poly.normalized_vertices[1].x *width, vertex.bounding_poly.normalized_vertices[1].y*height,\n",
    "            vertex.bounding_poly.normalized_vertices[2].x *width, vertex.bounding_poly.normalized_vertices[2].y*height,\n",
    "            vertex.bounding_poly.normalized_vertices[3].x *width, vertex.bounding_poly.normalized_vertices[3].y*height], None, 'red')\n",
    "    im.save('static/output.jpg', 'JPEG')\n",
    "    return result\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    \"\"\"\n",
    "    This Object Detector gets user's voice input (code word \"object\")\n",
    "    and takes a photo with the device's default camera,\n",
    "    then detects objects on it with Google Vision API\n",
    "    and returns audio output stating which object is in front of the user.\n",
    "    \"\"\"\n",
    "    photo = capture_img()\n",
    "    if photo is not None:\n",
    "        save_img(photo)\n",
    "        return google_vision(\"capture.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-advertiser",
   "metadata": {},
   "source": [
    "# Integration in flask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-promise",
   "metadata": {},
   "source": [
    "## Flask Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "polyphonic-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from flask import Flask, render_template,request, redirect, url_for\n",
    "import sys\n",
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "frank-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "UPLOAD_FOLDER = 'C:/Users/User/Documents/capstone/website_practice/upload/train'\n",
    "ALLOWED_EXTENSIONS = set(['png', 'jpg', 'jpeg'])\n",
    "app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 0\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "instant-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.after_request\n",
    "def add_header(r):\n",
    "    r.headers[\"Cache-Control\"] = \"no-cache, no-store, must-revalidate\"\n",
    "    r.headers[\"Pragma\"] = \"no-cache\"\n",
    "    r.headers[\"Expires\"] = \"0\"\n",
    "    r.headers['Cache-Control'] = 'public, max-age=0'\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-factory",
   "metadata": {},
   "source": [
    "## Index Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sacred-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default page of our web-app\n",
    "@app.route('/')\n",
    "@app.route('/home')\n",
    "def home():\n",
    "    return render_template('index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-harvest",
   "metadata": {},
   "source": [
    "## Facial Recognition Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "three-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/face_recog/')\n",
    "def face_recog():\n",
    "    return render_template('facerecog.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "meaningful-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/face_result')\n",
    "def face_result():\n",
    "    return recog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "expired-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/detect_face/')\n",
    "def detect_face():\n",
    "    return render_template('face_result.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "institutional-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/uploader', methods = ['GET', 'POST'])\n",
    "def upload_file():\n",
    "    if request.method == 'POST':\n",
    "        file = request.files['file']\n",
    "        text = request.form['text']\n",
    "        # if user does not select file, browser also\n",
    "        # submit a empty part without filename\n",
    "        if file.filename == '':\n",
    "            return redirect(url_for('face_recog'))\n",
    "        if file and text:\n",
    "            file_name = text + \".jpg\"\n",
    "            file.save(os.path.join(app.config['UPLOAD_FOLDER'], file_name))\n",
    "            return redirect(url_for('face_recog'))\n",
    "    else:\n",
    "        return redirect(url_for('face_recog'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-living",
   "metadata": {},
   "source": [
    "## Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "related-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/object_detection/')\n",
    "def object_detection():\n",
    "    result = main()\n",
    "    return render_template('object_detection.html', text = result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acute-karen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [07/Apr/2021 17:48:29] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:48:30] \"\u001b[36mGET /static/css/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:48:30] \"\u001b[33mGET /js/scripts.js HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:48:30] \"\u001b[33mGET /js/scripts.js HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:48:30] \"\u001b[36mGET /static/assets/img/city.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:48:50] \"\u001b[37mGET /object_detection/ HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:48:50] \"\u001b[36mGET /static/css/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:48:50] \"\u001b[33mGET /object_detection/js/scripts.js HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:48:50] \"\u001b[32mGET /static//loading.gif HTTP/1.1\u001b[0m\" 308 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:48:50] \"\u001b[36mGET /static/assets/img/city.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:48:51] \"\u001b[36mGET /static/loading.gif HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:48:56] \"\u001b[32mGET /static//output.jpg HTTP/1.1\u001b[0m\" 308 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:48:56] \"\u001b[37mGET /static/output.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:03] \"\u001b[37mGET /object_detection/ HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:03] \"\u001b[36mGET /static/css/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:03] \"\u001b[33mGET /object_detection/js/scripts.js HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:03] \"\u001b[32mGET /static//loading.gif HTTP/1.1\u001b[0m\" 308 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:03] \"\u001b[36mGET /static/assets/img/city.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:03] \"\u001b[36mGET /static/loading.gif HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:03] \"\u001b[37mGET /static/favicon.ico HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:08] \"\u001b[32mGET /static//output.jpg HTTP/1.1\u001b[0m\" 308 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:08] \"\u001b[37mGET /static/output.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:18] \"\u001b[37mGET /face_recog/ HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:18] \"\u001b[33mGET /static/js/FaceRecognition.js HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:18] \"\u001b[36mGET /static/css/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:18] \"\u001b[36mGET /static/assets/img/city.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:23] \"\u001b[37mGET /detect_face/ HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:23] \"\u001b[36mGET /static/css/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:23] \"\u001b[33mGET /detect_face/js/scripts.js HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:23] \"\u001b[32mGET /static//loading.gif HTTP/1.1\u001b[0m\" 308 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:23] \"\u001b[36mGET /static/loading.gif HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:23] \"\u001b[36mGET /static/assets/img/city.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:23] \"\u001b[33mGET /detect_face/js/scripts.js HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:28] \"\u001b[32mGET /static//capture.png HTTP/1.1\u001b[0m\" 308 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:28] \"\u001b[37mGET /static/capture.png HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:45] \"\u001b[37mGET /detect_face/ HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:45] \"\u001b[36mGET /static/css/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:45] \"\u001b[33mGET /detect_face/js/scripts.js HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:45] \"\u001b[32mGET /static//loading.gif HTTP/1.1\u001b[0m\" 308 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:45] \"\u001b[36mGET /static/assets/img/city.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:45] \"\u001b[36mGET /static/loading.gif HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:45] \"\u001b[37mGET /face_result HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:46] \"\u001b[37mGET /static/favicon.ico HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:51] \"\u001b[32mGET /static//capture.png HTTP/1.1\u001b[0m\" 308 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:51] \"\u001b[37mGET /static/capture.png HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:58] \"\u001b[37mGET /detect_face/ HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:58] \"\u001b[36mGET /static/css/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:58] \"\u001b[33mGET /detect_face/js/scripts.js HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:58] \"\u001b[32mGET /static//loading.gif HTTP/1.1\u001b[0m\" 308 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:58] \"\u001b[36mGET /static/assets/img/city.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:58] \"\u001b[36mGET /static/loading.gif HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:58] \"\u001b[37mGET /face_result HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:49:58] \"\u001b[37mGET /static/favicon.ico HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:50:03] \"\u001b[32mGET /static//capture.png HTTP/1.1\u001b[0m\" 308 -\n",
      "127.0.0.1 - - [07/Apr/2021 17:50:03] \"\u001b[37mGET /static/capture.png HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:07:44] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:07:44] \"\u001b[36mGET /static/css/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:07:44] \"\u001b[33mGET /js/scripts.js HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:07:44] \"\u001b[36mGET /static/assets/img/city.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:07:46] \"\u001b[37mGET /face_recog/ HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:07:46] \"\u001b[36mGET /static/css/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:07:46] \"\u001b[33mGET /static/js/FaceRecognition.js HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:07:46] \"\u001b[36mGET /static/assets/img/city.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:07:48] \"\u001b[37mGET /detect_face/ HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:07:48] \"\u001b[36mGET /static/css/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:07:48] \"\u001b[33mGET /detect_face/js/scripts.js HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:07:48] \"\u001b[32mGET /static//loading.gif HTTP/1.1\u001b[0m\" 308 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:07:48] \"\u001b[36mGET /static/loading.gif HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:07:48] \"\u001b[36mGET /static/assets/img/city.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:07:48] \"\u001b[33mGET /detect_face/js/scripts.js HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:07:48] \"\u001b[37mGET /face_result HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:07:54] \"\u001b[32mGET /static//capture.png HTTP/1.1\u001b[0m\" 308 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:07:54] \"\u001b[37mGET /static/capture.png HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:08:11] \"\u001b[37mGET /detect_face/ HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:08:11] \"\u001b[36mGET /static/css/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:08:11] \"\u001b[33mGET /detect_face/js/scripts.js HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:08:11] \"\u001b[32mGET /static//loading.gif HTTP/1.1\u001b[0m\" 308 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:08:11] \"\u001b[36mGET /static/assets/img/city.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:08:11] \"\u001b[36mGET /static/loading.gif HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:08:11] \"\u001b[37mGET /face_result HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:08:12] \"\u001b[37mGET /static/favicon.ico HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:08:39] \"\u001b[32mGET /static//capture.png HTTP/1.1\u001b[0m\" 308 -\n",
      "127.0.0.1 - - [07/Apr/2021 19:08:39] \"\u001b[37mGET /static/capture.png HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "   app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-annex",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
